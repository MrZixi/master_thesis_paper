\newcommand{\eg}{\textit{e}.\textit{g}.}
\chapternonum{摘要}
% 机器翻译一直以来都是自然语言处理领域针对不同语言文字的一项重要技术。
自动歌曲翻译是机器翻译针对非常规语体的拓展性研究，这一任务旨在将歌曲的歌词文本翻译到另外一种语言中，同时要求翻译后歌词文本搭配相应旋律依然能以歌曲的形式呈现出来。
% 即翻译后歌词仍能以某种方式来进行艺术性的演唱并传达原意。
% 除了歌词近似诗词的语体问题以外，这样的翻译相比于一般的机器翻译任务增加了一项需要考虑的旋律乐谱信息。
歌声合成任务是根据歌词和乐谱，将二者规定的音高、时长和内容合成为人声音频的语音合成任务。自动歌曲翻译搭配良好的歌声合成效果进行翻唱自动合成可以让听众无需学习多国语言、乐理知识或具备演唱能力就能欣赏来自不同语言不同文化的经典歌曲的母语翻唱版本。
因此，本文提出构建能进行歌词翻译并给出翻译后歌词的合理唱法的共同翻译模型和基于扩散模型的高质量翻唱歌声合成模型以针对歌曲达到自动化地翻译翻唱目的。

本文首先提出一个能翻译歌词并给出合理的翻译后歌词与原旋律的对齐方式的共同翻译模型。本文提出的歌词和歌词-旋律对齐共同翻译模型是在自回归的基于Transformer的编码器-解码器翻译框架下的改进，模型使用音符表示池化嵌入层来利用歌词和对齐的输入信息对旋律进行编码，为模型在进行歌词翻译的解码时加入对齐情况和信息和旋律信息。模型使用的轻量的对齐解码器采用自适应的分组算法来单调地预测歌词和旋律的对齐情况。在本文标注的歌曲翻译数据集上进行的一系列实验说明本文提出的歌词和翻译后歌词与原旋律的对齐方式的共同翻译模型相比其他歌曲翻译基线模型取得了更好的文本翻译表现和更为合理、更有表现力的歌词-旋律对齐预测，从而获得了更好的歌曲翻译表现。
其次，本文提出基于扩散模型的翻唱歌声合成声学模型，利用扩散模型在训练时进行噪声估计以获得更精确的似然计算、在推理时将旋律和歌词作为条件分若干步进行去噪重建，以获得更清晰、细节更丰富的梅尔频谱预测结果。该模型能适配歌曲翻译模型输出的歌词和歌词-旋律对齐信息，合成较高质量的梅尔频谱。在歌声数据集上的实验结果说明本文提出的模型相比其他歌声合成模型取得了更优质的歌声合成质量，且训练稳定，有较好的翻唱歌声合成效果。

\noindent\textbf{关键词：}~歌曲翻译；歌词-旋律对齐；歌声合成；扩散模型；对抗训练
\chapternonum{Abstract}
% Machine translation has always been an important technology for different languages in the community of Natural Language Processing.
Automatic song translation is an expanded research of machine translation on unconventional language styles, which is lyrics. This task aims to translate the lyrics of songs into another language while the translated lyrics text with corresponding melody can still be presented in the form of songs.
% , that is, the translated lyrics can still be performed as artistic singing and convey the original meaning accurately.
% In addition to the stylistic problem that lyrics are some kind of poetic verses, such translation has a music score that needs to be considered, compared with general machine translation tasks.
Singing voice synthesis task is a voice synthesis task that synthesizes singing voice audio conditioned on the pitch, duration and content specified by the lyrics and the corresponding music score. Automatic song translation with singing voice synthesis for automatic cover singing synthesis allows the audience to enjoy the mother tongue cover version of classic songs from different languages and cultures without mastering other languages, music theory knowledge or singing ability.
Therefore, this paper proposes to build a co-translation model that can translate lyrics and provide reasonable lyrics-melody alignments for translated lyrics, and a high-quality cover singing voice synthesis model based on the diffusion model to achieve the goal of automatic translation and cover singing sythesis for songs.

Firstly, we proposes a co-translation model that can translate lyrics and give a reasonable alignment between the translated lyrics and the original melody. The co-translation model of lyrics and lyrics-melody alignment proposed in this paper is an improvement under the autoregressive Transformer encoder-decoder translation framework. Our proposed model has a note-pooling embedding layer to encode the melody with alignment. It conveys the alignment and information and melody information to the translation decoder for lyrics text translation. The light-weight alignment decoder used in the model adopts an adaptive grouping algorithm to monotonously predict the alignment between lyrics and melody. Experiments conducted on the song translation dataset, annotated in this paper, show that the co-translation model has achieved better translation performance as well as more reasonable and more expressive lyrics melody alignment than other song translation baselines, thus obtaining better song translation performance.
% On the whole, the model has the ability to provide high-quality lyrics and score reference for cover singing.
Secondly, we proposes a synthetic acoustic model of cover singing synthesis based on diffusion model. The diffusion model is used to estimate the noise during training to obtain more accurate likelihood calculation. During inference, the melody and lyrics are used as conditions to denoise and reconstruct clear and more detailed Mel spectrum in several steps. The model can adapt to the lyrics and lyrics-melody alignment output from the AST model and synthesize high-quality Mel spectrum. Experimental results on the SVS dataset show that our model has achieved higher song synthesis quality than other baseline models. Meanwhile our model is stable to train with similar amount of parameters to other baselines.
% Secondly, we proposes an acoustic model of cover singing voice synthesis based on diffusion model adversarial training. This model can adapt to the lyrics and lyrics melody alignment information output from the song translation model. The experimental results on the singing voice synthesis dataset show that our model achieves better synthesis quality than other baseline models.

\noindent\textbf{Keywords:}~song translation; lyrics-melody alignments; singing voice synthesis; diffusion model; adversarial training
